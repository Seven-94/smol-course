# Instruction Tuning

Ce module vous guidera dans la mise au point des mod√®les linguistiques. L'ajustement des instructions consiste √† adapter des mod√®les pr√©-entra√Æn√©s √† des t√¢ches sp√©cifiques en les entra√Ænant de nouveau sur des ensembles de donn√©es sp√©cifiques √† ces t√¢ches. Ce processus permet aux mod√®les d'am√©liorer leurs performances sur les t√¢ches cibl√©es. 

Dans ce module, nous allons explorer deux sujets : 1) les mod√®les de conversation et 2) le r√©glage fin supervis√©.

## 1Ô∏è‚É£ Mod√®les de conversation

Les mod√®les de conversation structurent les interactions entre les utilisateurs et les mod√®les d'IA, garantissant des r√©ponses coh√©rentes et adapt√©es au contexte. Ils comprennent des √©l√©ments tels que les invites du syst√®me et les messages bas√©s sur le r√¥le. Pour plus d'informations, consultez la section [Chat Templates](./chat_templates.md).

## 2Ô∏è‚É£ Fine-Tuning Supervis√©

Le r√©glage fin supervis√© (SFT) est un processus essentiel pour adapter les mod√®les linguistiques pr√©-entra√Æn√©s √† des t√¢ches sp√©cifiques. Il s'agit d'entra√Æner le mod√®le sur un ensemble de donn√©es sp√©cifiques √† une t√¢che, avec des exemples √©tiquet√©s. Pour un guide d√©taill√© sur le SFT, y compris les √©tapes cl√©s et les meilleures pratiques, voir le document [Supervised Fine-Tuning](./supervised_fine_tuning.md).

## Cahiers d'exercices

| Titre | Description | Exercice | Lien | Colab |
|-------|-------------|----------|------|-------|
| Mod√®les de conversation | Apprenez √† utiliser les mod√®les de chat avec SmolLM2 et √† traiter les ensembles de donn√©es au format chatml. | üê¢ Convertir le jeu de donn√©es(dataset) `HuggingFaceTB/smoltalk` dans un format chatml <br> üêï Convertir le dataset `openai/gsm8k` dans un format chatml | [Notebook](./notebooks/chat_templates_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/chat_templates_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |
| Fine-Tuning Supervis√© | Apprenez √† affiner(fine-tune) SmolLM2 √† l'aide du SFTTrainer | üê¢ Utilisez le dataset `HuggingFaceTB/smoltalk` <br>üêï Essayez le dataset `bigcode/the-stack-smol` <br>ü¶Å S√©lectionner un jeu de donn√©es(dataset) pour un cas d'utilisation r√©el | [Notebook](./notebooks/sft_finetuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/sft_finetuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |

## References

- [Transformers documentation on chat templates](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Script for Supervised Fine-Tuning in TRL](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
- [`SFTTrainer` in TRL](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [Direct Preference Optimization Paper](https://arxiv.org/abs/2305.18290)
- [Supervised Fine-Tuning with TRL](https://huggingface.co/docs/trl/main/en/tutorials/supervised_finetuning)
- [How to fine-tune Google Gemma with ChatML and Hugging Face TRL](https://www.philschmid.de/fine-tune-google-gemma)
- [Fine-tuning LLM to Generate Persian Product Catalogs in JSON Format](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_format)
